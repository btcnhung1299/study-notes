**Ultimate goal**: In reinforcement learning problem, we want the agent to learn to act in order to maximise its goal. That is, for different type of RL, we want the following:
- Passive RL (fixed [[policy]] $\pi$): learn the [[utility]] $U$
- Active RL: learn the [[utility]] $U$ in association with the policy $\pi$ (that is balanced between exploitation and exploration)

**Reinforcement learning algorithms**:
- [[Direct Utility Estimation]]
- [[Temporal-Difference (TD)]]
- [[Q-learning]]

**Experiments**:
- Environements: https://gym.openai.com/envs/
- Results: plot charts of *return vs. timestep*